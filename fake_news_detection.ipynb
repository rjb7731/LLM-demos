{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb579f9",
   "metadata": {},
   "source": [
    "<h1>Predicting Fake news with a Bidirectional Encoder (BERT) + LSTM model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8008089",
   "metadata": {},
   "source": [
    "<h3>Based off me reading this <a href=\"https://www.sciencedirect.com/science/article/pii/S2405844023075904\">Paper</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee45319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "csv_files = ['politifact_fake.csv', 'gossipcop_fake.csv', 'gossipcop_real.csv', 'politifact_real.csv']\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of files and read each file into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    if \"fake\" in file: \n",
    "        df[\"verdict\"] = \"Fake\"\n",
    "    else:\n",
    "        df[\"verdict\"] = \"True\"\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145c8d1",
   "metadata": {},
   "source": [
    "<h3> The data comes from a dataset release called FakeNewsNet its a combination of data from politifact a user contributed site along with a site called gossipcon with the same concept</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb7ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23196, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8815f09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_url</th>\n",
       "      <th>title</th>\n",
       "      <th>tweet_ids</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>gossipcop-2895484840</td>\n",
       "      <td>www.magzter.com/article/Celebrity/OK/Taylors-L...</td>\n",
       "      <td>Taylor's Lonely Life</td>\n",
       "      <td>279594449154232321\\t280553081064800256\\t280797...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>gossipcop-884847</td>\n",
       "      <td>https://www.longroom.com/discussion/720445/wat...</td>\n",
       "      <td>Watch \"Belligerent\" Scott Disick Freak Out at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>gossipcop-3662901506</td>\n",
       "      <td>radaronline.com/videos/ellen-degeneres-talk-sh...</td>\n",
       "      <td>Boss From Hell! Ellen DeGeneres Treats Her Tal...</td>\n",
       "      <td>943461276277231616\\t943471999036411904\\t943499...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>gossipcop-925000</td>\n",
       "      <td>https://www.pinterest.co.uk/pin/29533768803792...</td>\n",
       "      <td>Fearless from Beyoncé and Jay Z's Vacation Pics</td>\n",
       "      <td>981654072489947136</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>gossipcop-907444</td>\n",
       "      <td>https://www.usmagazine.com/celebrity-news/news...</td>\n",
       "      <td>James Franco to Attend SAG Awards 2018 Amid Mi...</td>\n",
       "      <td>954377483410960386\\t954389751481675778\\t954389...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "7526   gossipcop-2895484840   \n",
       "4351       gossipcop-884847   \n",
       "10822  gossipcop-3662901506   \n",
       "5118       gossipcop-925000   \n",
       "4236       gossipcop-907444   \n",
       "\n",
       "                                                news_url  \\\n",
       "7526   www.magzter.com/article/Celebrity/OK/Taylors-L...   \n",
       "4351   https://www.longroom.com/discussion/720445/wat...   \n",
       "10822  radaronline.com/videos/ellen-degeneres-talk-sh...   \n",
       "5118   https://www.pinterest.co.uk/pin/29533768803792...   \n",
       "4236   https://www.usmagazine.com/celebrity-news/news...   \n",
       "\n",
       "                                                   title  \\\n",
       "7526                                Taylor's Lonely Life   \n",
       "4351   Watch \"Belligerent\" Scott Disick Freak Out at ...   \n",
       "10822  Boss From Hell! Ellen DeGeneres Treats Her Tal...   \n",
       "5118     Fearless from Beyoncé and Jay Z's Vacation Pics   \n",
       "4236   James Franco to Attend SAG Awards 2018 Amid Mi...   \n",
       "\n",
       "                                               tweet_ids verdict  \n",
       "7526   279594449154232321\\t280553081064800256\\t280797...    Fake  \n",
       "4351                                                 NaN    True  \n",
       "10822  943461276277231616\\t943471999036411904\\t943499...    Fake  \n",
       "5118                                  981654072489947136    True  \n",
       "4236   954377483410960386\\t954389751481675778\\t954389...    True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12ec5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>17441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>5755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verdict  count\n",
       "0    True  17441\n",
       "1    Fake   5755"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"verdict\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b46b28",
   "metadata": {},
   "source": [
    "<h2> Bit of a class imbalance on real vs fake so will sample the same amount of True </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fef50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_0_25 = df[df['verdict'] == 'True'].sample(n=5755, random_state=42)\n",
    "rest_df = df[df['verdict'] != 'True']\n",
    "df = pd.concat([sampled_0_25, rest_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d693143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>5755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verdict  count\n",
       "0    True   5755\n",
       "1    Fake   5755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"verdict\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b423e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "texts = df[\"title\"].to_list()\n",
    "\n",
    "labels = label_encoder.fit_transform(df[\"verdict\"].to_list())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, \n",
    "    test_size=0.2,  # 20% of the data for testing\n",
    "    stratify=labels,  # This ensures the distribution of labels is similar in both sets\n",
    "    random_state=42  # For reproducibility of results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1362d155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 1:   0%|                                          | 0/576 [00:00<?, ?it/s]/var/folders/hz/7cmfzpgd2r73sm28bjt1p0lr0000gp/T/ipykernel_95555/1252877392.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1: 100%|███████████████| 576/576 [01:29<00:00,  6.41it/s, mean_loss=0.576]\n",
      "Epoch 2: 100%|███████████████| 576/576 [01:29<00:00,  6.41it/s, mean_loss=0.527]\n",
      "Epoch 3: 100%|███████████████| 576/576 [01:30<00:00,  6.40it/s, mean_loss=0.491]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PolitifactDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure label tensors are long type\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class BertLSTM(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', hidden_dim=256, lstm_layers=1, dropout=0.1, num_classes=2):\n",
    "        super(BertLSTM, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_dim, num_layers=lstm_layers, batch_first=True, dropout=dropout if lstm_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        lstm_output, (h_n, c_n) = self.lstm(sequence_output)\n",
    "        lstm_output = self.dropout(lstm_output[:, -1, :])\n",
    "        logits = self.classifier(lstm_output)\n",
    "        return logits\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizing the texts\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Creating the datasets\n",
    "train_dataset = PolitifactDataset(train_encodings, y_train)\n",
    "test_dataset = PolitifactDataset(test_encodings, y_test)\n",
    "\n",
    "# Model\n",
    "model = BertLSTM()\n",
    "\n",
    "# Working with myt MPS on macbook M1\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoader setup - batch size of 16..\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop:\n",
    "for epoch in range(3):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0.0 \n",
    "    num_batches = 0  # Count the number of batches processed\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar with mean loss for the current epoch\n",
    "        progress_bar.set_postfix({'mean_loss': total_loss / num_batches})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a2280",
   "metadata": {},
   "source": [
    "<h2> Lets test out how well the model predicts on the reserved test set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a431fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                       | 0/144 [00:00<?, ?it/s]/var/folders/hz/7cmfzpgd2r73sm28bjt1p0lr0000gp/T/ipykernel_95555/1252877392.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Evaluating: 100%|█████████████████████████████| 144/144 [00:18<00:00,  7.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with no_grad():  # Inference mode, gradients not needed\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()  # Move predictions to CPU and convert to numpy\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())  # Move true labels to CPU and convert to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b22bc696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7346953742993346\n",
      "Accuracy: 0.7371850564726324\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.79      0.64      0.71      1151\n",
      "        True       0.70      0.83      0.76      1151\n",
      "\n",
      "    accuracy                           0.74      2302\n",
      "   macro avg       0.75      0.74      0.73      2302\n",
      "weighted avg       0.75      0.74      0.73      2302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')  # 'weighted' accounts for label imbalance\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fcd601",
   "metadata": {},
   "source": [
    "<p> 73% is not too bad for a quick go- the paper said they got between 73% and 83% with DL</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90884d3",
   "metadata": {},
   "source": [
    "<h2> Lets test it on a article I saw posted in the x-gov AI channel</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc3d0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: true\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "input_ids = tokenizer([\"Disillusioned Businesses Discovering That AI Kind of Sucks.\"], truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "input_ids_test = input_ids['input_ids']\n",
    "attention_mask_test = input_ids['attention_mask']\n",
    "\n",
    "outputs = model(input_ids_test.to(device), attention_mask_test.to(device))\n",
    "logits = outputs\n",
    "predictions = torch.argmax(logits, dim=1).cpu().numpy()  # Move predictions to CPU and convert to numpy\n",
    "\n",
    "index_to_class = {0: \"fake\", 1: \"true\"}  # Adjust based on your actual classes\n",
    "\n",
    "predicted_label = index_to_class[predictions[0]]\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75928e",
   "metadata": {},
   "source": [
    "<h2> and one I have just made up</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc887839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: fake\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer([\"Aliens have landed in manchester\"], truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "input_ids_test = input_ids['input_ids']\n",
    "attention_mask_test = input_ids['attention_mask']\n",
    "\n",
    "outputs = model(input_ids_test.to(device), attention_mask_test.to(device))\n",
    "logits = outputs\n",
    "predictions = torch.argmax(logits, dim=1).cpu().numpy()  \n",
    "\n",
    "predicted_label = index_to_class[predictions[0]]\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa651f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
