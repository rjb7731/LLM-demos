{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56278f3",
   "metadata": {},
   "source": [
    "<h1> Training or finetuning GPT Models within a business or organisation (and its challenges).</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1cf15b",
   "metadata": {},
   "source": [
    "<font size=\"3\">The increasing popularity and use cases of Large Language models in real world applications is on the rise. One of the main challenges presenting business and organisations is tuning these models to their own use cases.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d54c3e",
   "metadata": {},
   "source": [
    "<h3>In this notebook I will explore options for training custom use cases for these models, relevant research papers and also the presented challenges.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d8554",
   "metadata": {},
   "source": [
    "<h1> #1 Training your own GPT level model. </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f80cc",
   "metadata": {},
   "source": [
    "<font size=\"3\">One of the main benefits of using the GPT architecture is that you can effectively chuck as much unstructured data at the model as possible and it can gain a predictive knowledge or at least learn the patterns of the data. This helps a model to generate new text based off your own.</font>\n",
    "\n",
    "<font size=\"3\">The challenge with this approach is that its a huge effort needing really skilled engineers (many of which are already highly paid in private companies) and huge costs in compute - in the following paper its estimated it costs about 3 million dollars just to train the model alone. Forgetting the cost of curating so much data and keeping this model up to date too. </font>\n",
    "\n",
    "<font size=\"3\">This would also only create a foundation model and you would need additional training to get it to respond conversationally in a chatGPT style - this is another huge task.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758f71c",
   "metadata": {},
   "source": [
    "<font size=\"3\"> See <b> BloombergGPT Paper</b>: https://arxiv.org/abs/2303.17564 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3350e",
   "metadata": {},
   "source": [
    "<h1> #2 Finetuning an existing Language Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4834f",
   "metadata": {},
   "source": [
    "<font size=\"3\"> An option currently presented, (Azure, Google are beginning to offer this service) is finetuning these models to specific use cases. </font>\n",
    "\n",
    "<font size=\"3\">  This approach does assume that your data is already organised, representative and within a format to train a language model. The format typically expected is a sort of question and answer such as prompt: [prompt text], Response: [prefered response] </font>\n",
    "\n",
    "\n",
    "<font size=\"3\"> This would potentially be a massive task and you can imagine within a huge organisation with lots of data how many examples you may need to train a model and transfer that knowledge effectively! </font>\n",
    "\n",
    "\n",
    "<font size=\"3\"> The below paper experiments with using LLMs (specifically gpt-3 and 4) to generate these datasets. *Its worth pointing out though that using OpenAI's outputs to train your own models commercially does break their terms of service!* </font>\n",
    "    \n",
    "<font size=\"3\"> We could use opensource Language models to create synthetic datasets but that would raise the question why you would use Azure, Google all together to finetune these models. I dont imagine Azure will be offering this service with opensource models too as they are all-in with OpenAI's closed-source models. </font>\n",
    "\n",
    "<font size=\"3\"> See **Orca LLM Paper** - https://arxiv.org/abs/2306.02707 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6362",
   "metadata": {},
   "source": [
    "<h1> Final Option - although technically it is not training a model! </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507770bf",
   "metadata": {},
   "source": [
    "<h2> #3 Prompt Engineering - given LLMs context with vector databases.  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00d47e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Some practices have been put in place to apply cosine similarity against a vector database and then whatever text is found feeding that into the prompt for the language model and asking it to return relevant information etc. </font>\n",
    "\n",
    "<font size=\"3\"> Although this is a hacky way to take advantage of LLMs. I am doubtful on its use cases in a production setting. Some questions to answer. </font>\n",
    "\n",
    "1. How do you ensure you retrieve the most relevant context for the model? Is applying cosine enough?\n",
    "2. How do you know the model wont hallucinate given the wrong context (think across documents) or it simply does not know what you feed in (*) ? Could be less of a problem with GPT-4 but still assumes the model knows specific organisational terms etc.\n",
    "3. Do Large Language models have big enough context windows to understand something fully?\n",
    "\n",
    "<font size=\"3\"> * <b> *You can ask these models to return nothing for things it does not know but this does not solve hallucinations completely.*</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
